# -*- coding: utf-8 -*-
"""Copy of cv7_zadani.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gG7BiSO5G1ZkgKQ3Mt65twT4wxFKxB1y

# Bayes Classifier
We want to find most probable class given data we obsere:
$y_k^* = argmax_{y_k} P(Y=y_k \mid X1=x_i,X2=x_j) = argmax_{y_k} \frac{P(Y=y_k ) P( X1=x_i,X2=x_j\mid Y=y_k)}{P( X1=x_i,X2=x_j)}=$

$= argmax_{y_k} P(Y=y_k ) P( X1=x_i,X2=x_j \mid Y=y_k )     $

For two features (or few features) and discrete distribution, we can find this distribution by simple counting in dataset $D$:
"""

import pandas as pd
import numpy as np


X1=np.array([0,1,0,1,1,0,1])
X2=np.array([0,1,1,1,0,0,1])
Y=np.array([0,1,1,1,1,1,0])

"""then  probability of $P(Y= y_k)$ can be find simply as frequency of this class - e.g. $P(Y= 1) = \frac{\#D\{Y=1\}}{|D|}$ :"""

p1=np.sum(Y==1)/np.size(Y)
print(p1)

"""and $ P(X1=x_i,X2=x_j |Y=y_k)$ is frequency of $x_j$ feature in samples with  $y_k$ - e.g. $ P(X1=1,X2=1|Y=1)=\frac{\#D\{X1=0 \wedge X2=1 \wedge Y=1\}}{\#D\{Y=1\}}$"""

p2=np.sum((X1==1)&(X2==1)&(Y==1))/np.sum(Y==1)
print(p2)

"""Calculate all probabilites  $p(k,j,i)$ (build a classifier) and predict new sample $x_{new}=[0,0]$:"""

p_x1_x2_y=np.zeros((2,2,2))
p_y=np.zeros(2)

for k in range(2):
  p_y[k]=np.sum(Y==k)/np.size(Y)
  for i in range(2):
    for j in range(2):
      p_x1_x2_y[k,i,j]=np.sum( (Y==k)&(X1==i)&(X2==j))/np.sum(Y==k)
  

out=p_y*p_x1_x2_y[:,0,0]
 
print(out)

print(out/sum(out))



# predict
f=np.array([0,0])    # zadej binarni vstupni vektor f

pred_1=np.sum( (Y==1)&(X1==f[0])&(X2==f[1]))/np.sum(Y==1) * np.sum(Y==1)/np.size(Y)
pred_0=np.sum( (Y==0)&(X1==f[0])&(X2==f[1]))/np.sum(Y==0) * np.sum(Y==0)/np.size(Y)

m = np.sum([pred_0,pred_1])
print([pred_0/m, pred_1/m])

"""# Naive Bayes

Naive bayes classification fro binary Bernouli features - (chodil na přednášky,učil se, měl na zkoušce kocovinu)->(známka):
"""

# data generation
import numpy as np
import pandas as pd
np.random.seed(9789)
names=['Abadon','Abigail','Abiha','Abdon','Ábel','Abelard','Abraham','Absolon','Adalbert','Adam','Adéla','Adin','Adina','Adolf','Adrian','Adrián','Adriana','Adrien','Adriena','Agáta','Agaton','Aglaja','Achil','Achiles','Aida','Ailill','Alan','Alban','Albert','Albín','Albína','Albrecht','Aldo','Alen','Alena','Aleš','Alex','Alexandr','Alexandra','Alexej','Alfons','Alfréd','Alice','Alida','Alin','Alina','Alois','Aloisie','Alojz','Alruna','Alva','Alvar','Alvin','Alyson','Alžběta','Amadeus','Amálie','Amanda','Amát','Ambrož','Amon','Amos','Anabela','Anastázie','Anděla','Andrea','Andreas','Andrei','Andrej','Aneta','Anežka','Angela','Angus','Anita','Anna','Annaliesa','Annika','Antal','Antonie','Antonín','Apolena','Apolo','Arabela','Aranka','Areta','Ariadna','Arian','Ariana','Ariela','Arion','Arleta','Armando','Armida','Armin','Arnold','Arnošt','Aron','Arpád','Artur','Astrid','Atila','Atilla','Attila','Augustin','Augustýn','Aurora','Aurelio','Aya','Axel','Barabáš','Barbora','Bartoloměj','Baek - Korejské jméno.','Beáta','Bedřich','Bela','Běla','Belinda','Benedikt','Benjamin','Beno','Berenika','Bernadeta','Bernard','Berta','Bertram','Bianka','Bibiana','Blahomil','Blahomír','Blahoslav','Blanka','Blažej','Blažena','Bob','Bohdan','Bohdana','Bohuchval','Bohumil','Bohumila','Bohumír','Bohuslav','Bohuslava','Bojan','Bolemír','Boleslav','Bonaventura','Bonifác','Boris','Borislav','Bořek','Bořivoj','Božena','Božetěch','Božidar','Božidara','Brigita','Bronislav','Bruno','Brunhilda','Bratislav','Bryan','Břetislav','Bruce','Carmen','Cecil','Celestýn','Celestýna','Cecílie','Crha','Ctibor','Ctirad','Ctislav','Cyprián','Cyril','Čeněk','Česlav','Česlava','Čestmír','Dag','Dagmar','Daisy','Dalibor','Dalimil','Dana','Dan','Daniel','Daniela','Danuše','Darina','Darja','David','Deana','Denis','Denisa','Deodatus','Diana','Dimitris','Dita','Dobromil','Dobromila','Dobroslav','Dominik','Dominika','Donna','Dorian','Dorin','Dorota','Doubravka','Dmitr','Drahomír','Drahomíra','Drahoslav','Drahoslava','Dušan','Džamil','Džamila','Edita','Eduard','Edwulf','Eithne','Egon','Ela','Elena','Ellen','Eleonora','Eli','Elisa','Eliáš','Elisabeta','Eliška','Elke','Elza','Ema','Emanuel','Emil','Emílie','Emily','Emma','Ena','Engelbert','Erik','Erika','Ervín','Ester','Etel','Euniké','Eva','Evelína','Evžen','Evžénie','Eydís','Fabian','Fabio','Felix','Ferdinand','Filip','Filipa','Fiona','Fjodor','Florian','Floriana','Florin','Fridolín','František','Františka','Felicia','Gabriel','Gabriela','Gabriella','Gerda','Geppetto','Gertruda','Gita','Gizela','Glauco','Glorie','Grace','Godric','Gorazd','Gustav','Gwenda','Gaster','Hadrián','Hana','Hanuš','Haštal','Háta','Havel','Hedvika','Heda','Helena','Helga','Herbert','Hermína','Hermiona','Heřman','Honza','Homer','Hortenzie','Horymír','Hostivín','Hubert','Hugo','Hynek','Chaim','Chajim','Cheyenne','Chrudoš','Christie','Chřen','Ida','Idunn','Ignác','Ignácie','Igor','Ilja','Ilona','Ingrid','Ingemar','Inka','Irena','Iris','Irma','Irmhild','Isabela','Isabella','Isolda','Iška','Iulian','Iva','Ivan','Ivana','Iveta','Ivo','Ivona','Izabela','Jáchym','Jakub','Jakubka','Jan','Jack','Jin','Jun','Jana','Jarmil','Jarmila','Jarolím','Jaromír','Jaromíra','Jaroslav','Jaroslava','Jeroným','Jasmin (jméno)','Jessika','Jindra','Jindřich','Jindřiška','Jiří','Jiřina','Jitka','Johana','John','Jolana','Jonáš','Jorga','Jorik','Josef','Joshua','Judita','Juliana','Julie','Julia','Julius','Justýna','Kamil','Kamila','Karel','Karina','Karla','Karolína','Kaspar','Kašpar','Kateřina','Katia','Katka','Katy','Kazimír','Kelly','Kevin','Klára','Krorona','Klaudie','Klement','Kliment','Konstantin','Koridon','Krasimír','Kristiana','Kristián','Kristina','Kristýna','Krystýna','Kryštof','Křesomysl','Květa','Květoslav','Květoslava','Kvido','Lada','Ladislav','Ladislava','Laura','Lenka','Leo','Lea','Leona','Leonard','Leontina','Leopold','Leoš','Lešek','Lia','Liběna','Libor','Libuše','Liliana','Linda','Lipan','Lisa','Livie','Lili','Ljuba','Lubomír','Lubor','Luboš','Lucian','Lucie','Luděk','Ludmila','Ludvík','Lumír','Lukáš','Lýdie','Magdaléna','Mahulena','Maja','Mája','Malia','Malika','Malvína','Marcel','Marcela','Marek','Marián','Mariana','Marie','Marika','Marin','Marina','Marisa','Marius','Markéta','Marlen','Marshall','Maroš','Marta','Martin','Martina','Matěj','Matouš','Matyáš','Matylda','Maxim','Maxmilián','Medard','Metoděj','Michaela','Michael','Mikeš','Mikuláš','Milada','Milan','Milena','Miloslav','Miloslava','Miloš','Miluše','Mircea','Miriam','Miron','Miroslav','Miroslava','Mlada','Mlhoš','Mnata','Mojmír','Monika','Muriel','Myra','Nicolae','Nefrika','Nicoleta','Nicola','Naďa','Naděžda','Narcis','Narcisa','Nastasja','Nastěnka','Natálie','Nataniel','Nataša','Nazarius','Neklan','Nela','Nelly','Nereus','Nezamysl','Nicu','Nidgar','Niels','Nika','Nikander','Nikanor','Nikasius','Nikefor','Nikeforos','Niket','Nikita','Nikodém','Nikol','Nikolas (popř. Nicolas či Nicholas)','Nikolaus','Nikoleta','Nikolita','Nikon','Nina','Ninoslav','Nivard','Noemi','Nonius','Nonna','Nonnosus','Nora','Norbert','Norman','Nymfa','Octavian','Odeta','Odin','Oldřich','Oldřiška','Oleg','Olga','Oliver','Olívie','Ondřej','Oskar','Otakar','Otmar','Oto','Otýlie','Olimpiada','Olin','Ondřejka','Olivia','Pankrác','Patricie','Patrik','Pavel','Pavla','Pavlín','Pavlína','Penelope','Petr','Petra','Pia','Pipin','Pius','Pnina','Pravoslav','Pribin','Prokop','Prokopa','Přemysl','Peregrin','Quido','Radana','Radan','Radek','Radim','Radka','Radmila','Radomír','Radoslav','Radovan','Raven','Radu','Rafael','Regína','Renáta','René','Restituta','Richard','Rita','Robert','Roberta','Robin','Rodan','Roderik','Roland','Roman','Romana','Ronald','Rosalinda','Rostislav','Rozálie','Rudolf','Rút','Růžena','Řehoř','Řeřich','Saaba (Sába)','Sabina','Salome','Sally','Samir','Samuel','Sandra','Sante','Sára','Saskie','Sáva','Sebastian','Sergei','Servác','Seth','Silvestr','Silva','Silvia','Silvie','Simon','Simona','Slavěna','Slavomír','Soběslav','Soběslava','Sofie','Soňa','Sorin','Spytihněv','Stanislav','Stanislava','Stela','Stelian','Strachota','Svatava','Svatopluk','Svatoslav','Světlana','Sven','Sylva','Sylvie','Šárka','Šarlota','Šimon','Štefan','Šťáhlav','Štěpán','Štěpánka','Šimona','Tadeáš','Talip','Tamara','Tara','Tarsicius','Taťána','Tea','Teodor','Tereza','Terezie','Tibor','Tobias','Tomáš','Toni','Trina','Tristan','Udo','Ulrika','Ulrich','Uma','Urban','Uršula','Uvo','Václav','Valdemar','Valentýn','Valentýna','Valerie','Vanda','Vanesa','Vavřinec','Věnceslav','Vendelín','Vendula','Věra','Veronika','Věroslav','Viktor','Viktorie','Vili','Vilém','Vilma','Vilemína','Vincenc','Viola','Violka','Vít','Vítězslav','Vlad','Vladan','Vladěna','Vladimír','Vladimíra','Vladislav','Vladivoj','Vlasta','Vlastimil','Vlastislav','Vnislav','Vojen','Vojtěch','Voršila','Vratislav','Vsevolod','Vanessa','Waldemar','Walter','William','Willow','Werner','Wolfgang','Wolfram','Xaver','Xaverie','Xaverius','Xena','Xenie','Yveta','Yva','Yvana','Yvan','Záboj','Zachar','Zachariáš','Záviš','Zbislav','Zbyhněv','Zbyhněva','Zbyněk','Zbyňka','Zbyslav','Zbyslava','Zbyšek','Zbyška','Zdena','Zdeněk','Zdenka','Zdeňka','Zderad','Zdeslav','Zdeslava','Zdík','Zdirad','Zdislav','Zdislava','Zeno','Zenobie','Zenon','Zikmund','Zina','Zinaida','Zita','Zlata','Zlatan','Zlatko','Zlatomír','Zlatomíra','Zlatuše','Zoe','Zoja','Zoltán','Zora','Zoran','Zoroslav','Zoroslava','Zosim','Zuzana','Zvonimír','Zvonimíra','Žakelína','Žakelina','Žaneta','Žarko','Ždan','Ždana','Želibor','Želimír','Želimíra','Želislav','Želislava','Želmír','Želmíra','Žibřid','Žitomír','Žitomíra','Žitoslav','Žitoslava','Živa','Živan','Živana','Žofie','Žukelína','Abrahám','Absolón','Árón','Celestina','Florián','Glórie','Isolde','Jasmína','Nikola','Aaron']
n=200
names=np.random.choice(names,size=(n))
Y=np.random.choice(('A','B','C','D','E','F'),size=(n),p=(0.1,0.2,0.2,0.1,0.1,0.3))
X=np.zeros((n,3))
for k,grade in enumerate(['A','B','C','D','E','F']):
  a=5
  pst=np.array([13-k,2+k])
  pst=pst/np.sum(pst)
  X[Y==grade,0]=np.random.choice((0,1),size=(np.sum(Y==grade)),p=pst)
  pst=np.array([9-k,2+k])
  pst=pst/np.sum(pst)
  X[Y==grade,1]=np.random.choice((0,1),size=(np.sum(Y==grade)),p=pst)
  pst=np.array([2+k,10-k])
  pst=pst/np.sum(pst)
  X[Y==grade,2]=np.random.choice((0,1),size=(np.sum(Y==grade)),p=pst)
  
X=(1-X)>0
  
### dataframe for visualisation
df = pd.DataFrame({'jméno': names,'chodil na přednášky': X[:,0] ,'učil se': X[:,1], 'měl kocovinu': X[:,2],'známka': Y })
df

"""Calculate all $\theta_{i,k}$ (build a classifier)


and predict new sample $x_{new}=[1,1,1]$ (snaživý student s kocovinou) and plot a histogram of probabilities for this sample:
"""

znamky=['A','B','C','D','E','F']
X.shape

def bernoulli(x,theta):
  return theta**x*(1-theta)**(1-x)

### find all theta_ik
theta_ik = np.zeros((3,6))
p_y = np.zeros((6))

for k,znamka in enumerate(znamky):
  a=Y==znamka
  X1=X[:,0]
  theta_ik[0,k]=np.mean(X1[a])
  p_y[k] = np.mean(a)
  X2=X[:,1]
  theta_ik[1,k]=np.mean(X2[a])
  p_y[k] = np.mean(a)
  X3=X[:,2]
  theta_ik[2,k]=np.mean(X3[a])
  p_y[k] = np.mean(a)
  
#Platí to obecně, vždy vyberu daný příznak a pak jej fitují pomocí nějaké distribuce 
#V tomto případě je to Bernulli, ale může to být i Gaussovka, či cokoliv


x_new=np.array([1,1,1]) #Chci predikovat tady ten vzorek 
#Pro predikci
p=np.zeros(6)
for k,znamka in enumerate(znamky):  
  p[k] = p_y[k]*bernoulli(x_new[0],theta_ik[0,k])*bernoulli(x_new[1],theta_ik[1,k])*bernoulli(x_new[2],theta_ik[2,k])


### find all p(y_k)


### predict probability for all classes
p_norm = np.zeros(6)
for i in range(np.shape(p)[0]):
  p_norm[i]=p[i]/(np.sum(p))  

### normalize to sum 1

import matplotlib.pyplot as plt
plt.bar(['A','B','C','D','E','F'],p_norm)
plt.show()

"""# Naive bayes for images with Gaussian distribution of pixels

Load numbers 1 and 2 form  MNIST dataset:
"""

import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(9789)

loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=True, download=True,transform=torchvision.transforms.ToTensor()),batch_size=1, shuffle=True)

imgs=[]
lbls=[]
for  k, (data, targets) in enumerate(loader):
  lbl=targets.detach().cpu().numpy()
  if lbl==1 or lbl==2:
    imgs.append(data[0,0,:,:].detach().cpu().numpy()+0.2*np.random.rand(28,28))
    lbls.append(lbl)
  
  if k>5000:
    break

lbls=np.array(lbls)[:,0]
imgs=np.stack(imgs,axis=2)
split=int(np.round(len(lbls)*2/3))

imgs_train=imgs[...,:split]
imgs_test=imgs[...,split:]
lbls_train=lbls[:split]
lbls_test=lbls[split:]

print(imgs_train.shape)
print(imgs_test.shape)

for k in range(10):
  plt.imshow(imgs_train[:,:,k])
  plt.show()
  print(lbls_train[k])

"""We assume that every pixel came from Gausian distribution

$p(x_1 \mid y_k,\mu,\sigma^2 )=  \frac{1}{\sigma \sqrt{2 \pi}} exp(\frac{-(x_1-\mu)^2}{2\sigma^2})$

MLE solution:

$\hat{\mu} = ?$

$\hat{\sigma}^2 = ?$
"""

import numpy as np
import matplotlib.pyplot as plt

imgs_train_vec=imgs_train.reshape((28*28,-1))
imgs_test_vec=imgs_test.reshape((28*28,-1))



#Příznaky 28x28
mu = np.zeros((2,28*28))
sigma = np.zeros((2,28*28))
pyk=np.zeros((2))

for k in [1,2]:
  pyk[k-1]=np.mean(lbls_train==k)
  for i in range(28*28):
    x = imgs_train_vec[i,:]
    x = x[lbls_train==k]
    mu[k-1,i]=np.mean(x)
    sigma[k-1,i]=np.std(x)

plt.imshow(mu[0,:].reshape((28,28)))

imgs_test_vec.shape

for q in range(20):
  plt.imshow(imgs_test[:,:,q])
  plt.show()
  img=imgs_test_vec[:,q]
  for k in [0,1]:
    mu_tmp=mu[k,:]
    sigma_tmp=sigma[k,:]

    G=(1/(sigma_tmp*np.sqrt(2*np.pi)))*np.exp(-(img-mu_tmp)**2/(2*sigma_tmp**2))
    print(np.sum(np.log(G))+np.log(pyk[k]))

print(imgs_test_flat[:,0])

"""# Gaussian mixture model

Probability model is mixture (sum) of weigthted Gaussians - with $d$ dimensions and $k$ Gaussians:

$p(\mathbf{x}|\mathbf{\theta})=\sum_{k=1}^{K}w_k p(\mathbf{x}|\mathbf{\theta}_k) =\sum_{k=1}^{K}w_k(2\pi)^{-d/2}|\Sigma_k|^{-1/2}exp\left[-\frac{1}{2} (\mathbf{x}-\mathbf{\mu}_k)^T\Sigma_k^{-1}(\mathbf{x}-\mathbf{\mu}_k)\right]$

### Expectation-Maximization (EM) algorithm

If we know asigments (probabilities $p_{ij}$) of datapoints to individual Gaussians, then we can fit $j$-th Gaussian with MLE (M-step):


$w_j=\frac{\sum\limits_{i} p_{ij} }{N}, \quad \mathbf{\mu}_j=\frac{\sum\limits_{i} p_{ij} \mathbf{x}_i} { \sum\limits_i p_{ij}}, \quad \Sigma_j=\frac{\sum\limits_{i} p_{ij}  (\mathbf{x}_i-\mu_j) (\mathbf{x}_i-\mu_j)^T}{\sum\limits_i p_{ij}}$

and if we know Gaussians parameters we can calculate probabilty that $i$-th point come from $j$-th Gaussian:

$p_{ij}=p(\mathbf{\theta}_k=\mathbf{\theta}_j|\mathbf{x}=\mathbf{x}_i)=\frac{w_j p(\mathbf{x=\mathbf{x}_i}|\mathbf{\theta}_k=\mathbf{\theta}_j)}{\sum\limits_{l=1}^{K}w_l p(\mathbf{x=\mathbf{x}_i}|\mathbf{\theta}_k=\mathbf{\theta}_l)}$

We cannot extimate both simultaneously, however, we can alternate between these two steps - simlarly to k-means.

Data generation:
"""

import numpy as np
from numpy.random import randn
import matplotlib.pyplot as plt
from IPython.core.debugger import set_trace

np.random.seed(801)

mu1 = np.array([1,2] )      
sigma1 = np.array([[ 1,.2],[.2,1]])  
m1 = 100          

mu2 = np.array([-1, -2])
sigma2 = np.array([[3, 0],[0, 1]])
m2 = 50

# raději generování standrtním vzorcem gausovky - bude pro studenty pochopitelnější
R1 = np.linalg.cholesky(sigma1)
X1 = np.matmul(randn(m1, 2) ,R1)
X1 = X1 + mu1

R2 = np.linalg.cholesky(sigma2)
X2 = np.matmul(randn(m2, 2), R2)
X2 = X2 + mu2

X = np.concatenate((X1,X2),axis=0)



plt.plot(X1[:,0],X1[:,1],'r*')
plt.plot(X2[:,0],X2[:,1],'b*')
plt.show()

plt.plot(X[:,0],X[:,1],'k*')
plt.show()

"""E-step


$p_{ij}=\frac{w_j p(\mathbf{x=\mathbf{x}_i}|\mathbf{\theta}_k=\mathbf{\theta}_j)}{\sum\limits_{l=1}^{K}w_l p(\mathbf{x=\mathbf{x}_i}|\mathbf{\theta}_k=\mathbf{\theta}_l)}$


M-step

$w_j=\frac{\sum\limits_{i} p_{ij} }{ N}, \quad \mathbf{\mu}_j=\frac{\sum\limits_{i} p_{ij} \mathbf{x}_i} { \sum\limits_i p_{ij}}, \quad \Sigma_j=\frac{\sum\limits_{i} p_{ij}  (\mathbf{x}_i-\mu_j) (\mathbf{x}_i-\mu_j)^T}{\sum\limits_i p_{ij}}$
"""

def plot_ellipse(ax, mu, sigma, color="b"):
    from matplotlib.patches import Ellipse
    # Compute eigenvalues and associated eigenvectors
    vals, vecs = np.linalg.eigh(sigma)

    # Compute "tilt" of ellipse using first eigenvector
    x, y = vecs[:, 0]
    theta = np.degrees(np.arctan2(y, x))

    # Eigenvalues give length of ellipse along each eigenvector
    w, h = 2 * np.sqrt(vals)
#     w,h=w*np.sqrt(2),h*np.sqrt(2)
    ellipse = Ellipse(mu, w, h, theta, color=color)  # color="k")
    ellipse.set_clip_box(ax.bbox)
    ellipse.set_alpha(0.2)
    ax.add_artist(ellipse) 
    
    
n,d=X.shape

# initialization
mu1=X[[0],:].T
mu2=X[[1],:].T
sig1=np.eye(2)
sig2=np.eye(2)
w1=1
w2=1
ax=plt.subplot(111)



p1=np.zeros(n)
p2=np.zeros(n)

#Aplikovat ty tři vzorce výše zde... 

for steps in range(30):
  # E-step
  #p[steps]= 

  for i in range(n):
    pass
    ### calculate p1[i], p2[i] and normalize
    dsig=np.linalg.det(sig1)
    isig=np.linalg.inv(sig1)
    mu=mu1
    p1[i]= w1*(1/(2*np.pi)*dsig**(-0.5))*np.exp(-0.5*(X[[i],:].T-mu)).T@isig@(X[[i],:].T-mu)

    dsig=np.linalg.det(sig2)
    isig=np.linalg.inv(sig2)
    mu=mu2
    p2[i]= w2*(1/(2*np.pi)*dsig**(-0.5))*np.exp(-0.5*(X[[i],:].T-mu)).T@isig@(X[[i],:].T-mu)

#w1 = np.sum(p1)/n
#w2 = np.sum(p2)/n
#mu1 = np.sum(p1*)   

ax=plt.subplot(111)
argmax=np.argmax(np.stack((p1,p2),axis=1),axis=1)
plt.plot(X[np.where(argmax==0)[0],0],X[np.where(argmax==0)[0],1],'b*')
plt.plot(X[np.where(argmax==1)[0],0],X[np.where(argmax==1)[0],1],'r*')
plot_ellipse(ax,mu1,sig1,color='b')
plot_ellipse(ax,mu2,sig2,color='r')
plt.show()





  ### update mus and sigmas

"""Generate new sample from GMM distribution:

(hint - randomly select Gaussian and use multivareite_normal to get sample)
"""

from numpy.random import multivariate_normal